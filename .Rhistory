docs <- tm_map(docs, stripWhitespace)
# Text stemming
# docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
warnings()
# # Install
# install.packages("tm")  # for text mining
# install.packages("SnowballC") # for text stemming
# install.packages("wordcloud") # word-cloud generator
# install.packages("RColorBrewer") # color palettes
# Load
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
# Read the text file from internet
filePath <- "http://www.sthda.com/sthda/RDoc/example-files/martin-luther-king-i-have-a-dream-speech.txt"
text <- readLines("E:\\paper.txt")
# Load the data as a corpus
docs <- Corpus(VectorSource(text))
inspect(docs)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
# docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
# # Install
# install.packages("tm")  # for text mining
# install.packages("SnowballC") # for text stemming
# install.packages("wordcloud") # word-cloud generator
# install.packages("RColorBrewer") # color palettes
# Load
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
# Read the text file from internet
filePath <- "http://www.sthda.com/sthda/RDoc/example-files/martin-luther-king-i-have-a-dream-speech.txt"
text <- readLines("E:\\paper.txt")
# Load the data as a corpus
docs <- Corpus(VectorSource(text))
inspect(docs)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
# docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
?toSpace
tm_map
?tm_map
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
toSpace <- content_transformer(function(x, pattern) {return (gsub(pattern, ” “, x))})
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs
inspect(docs)
docs <- tm_map(docs, toSpace, "]")
docs <- tm_map(docs, toSpace, "[")
# # Install
# install.packages("tm")  # for text mining
# install.packages("SnowballC") # for text stemming
# install.packages("wordcloud") # word-cloud generator
# install.packages("RColorBrewer") # color palettes
# Load
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
# Read the text file from internet
filePath <- "http://www.sthda.com/sthda/RDoc/example-files/martin-luther-king-i-have-a-dream-speech.txt"
text <- readLines("E:\\paper.txt")
# Load the data as a corpus
docs <- Corpus(VectorSource(text))
inspect(docs)
toSpace <- content_transformer(function(x, pattern) {return (gsub(pattern, ” “, x))})
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
# docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
# # Install
# install.packages("tm")  # for text mining
# install.packages("SnowballC") # for text stemming
# install.packages("wordcloud") # word-cloud generator
# install.packages("RColorBrewer") # color palettes
# Load
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
# Read the text file from internet
filePath <- "http://www.sthda.com/sthda/RDoc/example-files/martin-luther-king-i-have-a-dream-speech.txt"
# text <- readLines("E:\\paper.txt")
# Load the data as a corpus
docs <- Corpus(VectorSource(text))
inspect(docs)
toSpace <- content_transformer(function(x, pattern) {return (gsub(pattern, ” “, x))})
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
# docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
# # Install
# install.packages("tm")  # for text mining
# install.packages("SnowballC") # for text stemming
# install.packages("wordcloud") # word-cloud generator
# install.packages("RColorBrewer") # color palettes
# Load
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
# Read the text file from internet
filePath <- "http://www.sthda.com/sthda/RDoc/example-files/martin-luther-king-i-have-a-dream-speech.txt"
# text <- readLines("E:\\paper.txt")
# Load the data as a corpus
docs <- Corpus(VectorSource(text))
inspect(docs)
toSpace <- content_transformer(function(x, pattern) {return (gsub(pattern, ” “, x))})
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
# docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
# text <- readLines("E:\\paper.txt")
text <- readLines(filepath)
# Load the data as a corpus
docs <- Corpus(VectorSource(text))
inspect(docs)
toSpace <- content_transformer(function(x, pattern) {return (gsub(pattern, ” “, x))})
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
text <- readLines("E:\\paper.txt")
text <- readLines(filepath)
text <- readLines("E:\\paper.txt")
# Load the data as a corpus
docs <- Corpus(VectorSource(text))
inspect(docs)
docs <- tm_map(docs, toSpace, "[")
docs <- tm_map(docs, toSpace, "@")
mylist <- list(
Weight = c("9","11","14"),
Button = c("Circle","Square","Rectangle"),
Price = c("$199","$259","$359"),
Aspect_Ratio = c("0.35","0.55", "0.75", "0.90"),
Material = c("Aluminum", "Plastic", "Soft-Grip Plastic", "Extra-Strength Aluminum"),
Depth = c("1/5", "1/4", "1/3"),
Pen_Enclosure = ("Yes":"No")
)
mylist <- list(
Weight = c("9","11","14"),
Button = c("Circle","Square","Rectangle"),
Price = c("$199","$259","$359"),
Aspect_Ratio = c("0.35","0.55", "0.75", "0.90"),
Material = c("Aluminum", "Plastic", "Soft-Grip Plastic", "Extra-Strength Aluminum"),
Depth = c("1/5", "1/4", "1/3"),
Pen_Enclosure = ("Yes","No")
)
mylist <- list(
Weight = c("9","11","14"),
Button = c("Circle","Square","Rectangle"),
Price = c("$199","$259","$359"),
Aspect_Ratio = c("0.35","0.55", "0.75", "0.90"),
Material = c("Aluminum", "Plastic", "Soft-Grip Plastic", "Extra-Strength Aluminum"),
Depth = c("1/5", "1/4", "1/3"),
Pen_Enclosure = c("Yes","No")
)
list
mylist
x = 10
y = 100
x = 10
y = 100
x
y
x = 10
x = 10
y = 100
x
y
fname <- 'moein'
fname
x <- 10
age <- 1:10
age
# The command c()  creates a vector from
# a list of values. Let's check out:
age
# The command c()  creates a vector from
# a list of values. Let's check out:
age <- c(21, 32, 65, 24, 76)
# CTRL L clears the console.
# The command c()  creates a vector from
# a list of values. Let's check out:
age <- c(21, 32, 65, 24, 76)
?rep
rep(1:4, each = 2, times = 3)
rep(1:4, each = 2, times = 3)
rep(1:4, each = 2, times = 3)
# Alt - creates the assignment operator.
# CTRL L clears the console.
x <- 100
df <- data.frame(x = 1:5, y = c('a', 'b', 'c', 'd', 'e'))
df <- data.frame(x = 1:5, y = c('a', 'b', 'c', 'd', 'e'))
df <- data.frame(x = 1:5, y = c('a', 'b', 'c', 'd', 'e'))
View(df)
df
d1
d1 <- data.frame(x = 1:5, y = c('a', 'b', 'c', 'd', 'e'))
d1
View(d1)
# Get me the x column of d1
d1$x
d1$y
View(d1)
# Get me the value in row 3 and column 2
d1[ 3 , 2 ]
# Get me the second column
d1[ ,2]
# Get me the 4th row
d1[4, ]
View(d1)
[
s1 <- d1[ , 2]
d2 <- d1
d3 <- data.frame(d1 ,d2 )
View(d3)
View(d3)
fname <- 'moein'
x <- 10
age <- 1:10
# The command c()  creates a vector from
# a list of values. Let's check out:
age <- c(21, 32, 65, 24, 76)
# Alt - creates the assignment operator.
# CTRL L clears the console.
x <- 100
d1 <- data.frame(x = 1:5, y = c('a', 'b', 'c', 'd', 'e'))
# Get me the x column of d1
d1$x
d1$y
# Get me the value in row 3 and column 2
d1[ 3 , 2 ]
# Get me the second column
d1[ ,2]
# Get me the 4th row
d1[4, ]
# Empty space in brackets means all.
# Q1: create an object called s1
# and put the second column of d1 as its
# value
s1 <- d1[ , 2]
# create a copy of d1 and call it d2
d2 <- d1
# create a new dataframe called d3 consisting of d1 and d2, side by side
d3 <- data.frame(d1 ,d2 )
fname <- 'moein'
x <- 10
age <- 1:10
# The command c()  creates a vector from
# a list of values. Let's check out:
age <- c(21, 32, 65, 24, 76)
# Alt - creates the assignment operator.
# CTRL L clears the console.
x <- 100
d1 <- data.frame(x = 1:5, y = c('a', 'b', 'c', 'd', 'e'))
# Get me the x column of d1
d1$x
d1$y
# Get me the value in row 3 and column 2
d1[ 3 , 2 ]
# Get me the second column
d1[ ,2]
# Get me the 4th row
d1[4, ]
# Empty space in brackets means all.
# Q1: create an object called s1
# and put the second column of d1 as its
# value
s1 <- d1[ , 2]
# create a copy of d1 and call it d2
d2 <- d1
# create a new dataframe called d3 consisting of d1 and d2, side by side
d3 <- data.frame(d1 ,d2 )
d3 <- data.frame(d1 ,d2 )
View(d3)
View(d3)
lastname <- 'Jackson'
lastname
x <- 10
x
x
x
name <- 'Jackson'
x <- 10
age <- 1:10
age <- 100:120
c
c
c(1,43,5,4,3)
# The command c()  creates a vector from
# a list of values. Let's check out:
age <- c(21, 32, 65, 24, 76)
age <- 1:10
# The command c()  creates a vector from
# a list of values. Let's check out:
age <- c(21, 32, 65, 24, 76)
# Alt - creates the assignment operator.
# CTRL L clears the console.
x <- 100
data.frame
x = 1:5
x = 1:5
y = c('a', 'b', 'c', 'd', 'e')
data.frame(x, y)
data.frame(x = 1:5, y = c('a', 'b', 'c', 'd', 'e'))
5, y = c('a', 'b', 'c', 'd', 'e')
# Get me the x column of d1
column
# Get me the x column of d1
nrow(d1)
d1 <- data.frame(x = 1:5, y = c('a', 'b', 'c', 'd', 'e'))
nrow(d1)
ncol(d1)
dim(d1)
seq(2, 3, by=0.5)
seq(2, 30, by=0.5)
seq(2, 30, by=0.25)
rep(1:2, times=3)
rep(1:2, times=30)
rep(1:2, each=30)
?seq
c(jan, feb, mar)
c(jan, feb, mar)
c('jan', 'feb', 'mar')
x <- c('jan', 'feb', 'mar')
rep(x, times=5)
rep(x, times=5)
months <- rep(x, times=5)
months
months
months <- rep(c('jan', 'feb', 'mar'), times=5)
months
if (!require("devtools")) install.packages("devtools")
library("devtools")
devtools::install_github("klutometis/roxygen")
library(roxygen2)
if (!require(rstudioapi)) install.packages("rstudioapi")
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
create("marketing")
if (!require("devtools")) install.packages("devtools")
library("devtools")
devtools::install_github("klutometis/roxygen")
library(roxygen2)
if (!require(rstudioapi)) install.packages("rstudioapi")
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
create("mktgfunctions")
setwd("./mktgfunctions")
document()
# Remove all variables from memory to start fresh
rm(list=ls())
# If there are plots, delete them to start fresh
if (length(dev.list())!= 0) dev.off()
if (!require(rstudioapi)) install.packages("rstudioapi")
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
####################################################
if (!require(devtools)) install.packages("devtools")
devtools::install_github("1moein/mktgfunctions")
search()
